{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bb7934",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bf0d0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\xavysp\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2.15.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "# from model import model_maker\n",
    "# from model2 import model_maker\n",
    "from model3 import model_maker\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3cdfd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab73ad75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_maker(dataset_name):\n",
    "    \n",
    "    if dataset_name ==\"mnist_fashion\":\n",
    "        \n",
    "        fashion_mnist = keras.datasets.fashion_mnist\n",
    "        (x_full,y_full),(x_test,y_test)=fashion_mnist.load_data()\n",
    "\n",
    "        x_valid, x_train = x_full[:5000] / 255.0, x_full[5000:] / 255.0\n",
    "        y_valid, y_train = y_full[:5000], y_full[5000:]\n",
    "        x_test = x_test / 255.0\n",
    "\n",
    "        class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \n",
    "                       \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]\n",
    "\n",
    "        x_train = x_train.reshape((55000, 28, 28, 1))\n",
    "        x_valid = x_valid.reshape((5000, 28, 28, 1))\n",
    "        x_test = x_test.reshape((10000, 28, 28, 1))\n",
    "        \n",
    "        return [x_train,y_train], [x_valid, y_valid], [x_test, y_test]\n",
    "    \n",
    "    elif dataset_name ==\"mnist\":\n",
    "        # train 60000 test 10000\n",
    "        (x_full, y_full), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "        \n",
    "        x_valid, x_train = x_full[:5000] / 255.0, x_full[5000:] / 255.0\n",
    "        y_valid, y_train = y_full[:5000], y_full[5000:]\n",
    "        x_test = x_test / 255.0\n",
    "        \n",
    "        x_train = x_train.reshape((55000, 28, 28, 1))\n",
    "        x_valid = x_valid.reshape((5000, 28, 28, 1))\n",
    "        x_test = x_test.reshape((10000, 28, 28, 1))\n",
    "        \n",
    "        return [x_train,y_train], [x_valid, y_valid], [x_test, y_test]\n",
    "    \n",
    "    elif dataset_name ==\"cifar10\":\n",
    "        # train 50000, 10000\n",
    "        (x_full, y_full), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "        \n",
    "        x_valid, x_train = x_full[:5000] / 255.0, x_full[5000:] / 255.0\n",
    "        y_valid, y_train = y_full[:5000], y_full[5000:]\n",
    "        x_test = x_test / 255.0\n",
    "        \n",
    "        class_names = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \n",
    "                       \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "        \n",
    "        x_train = x_train.reshape((45000, 32, 32, 3))\n",
    "        x_valid = x_valid.reshape((5000, 32, 32, 3))\n",
    "        x_test = x_test.reshape((10000, 32, 32, 3))\n",
    "        \n",
    "        return [x_train,y_train], [x_valid, y_valid], [x_test, y_test]\n",
    "    \n",
    "    elif dataset_name ==\"cifar100\":\n",
    "        # train 50000, 10000\n",
    "        (x_full, y_full), (x_test, y_test) = keras.datasets.cifar100.load_data()\n",
    "        \n",
    "        x_valid, x_train = x_full[:5000] / 255.0, x_full[5000:] / 255.0\n",
    "        y_valid, y_train = y_full[:5000], y_full[5000:]\n",
    "        x_test = x_test / 255.0\n",
    "        \n",
    "        class_names = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \n",
    "                       \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n",
    "        \n",
    "        x_train = x_train.reshape((45000, 32, 32, 3))\n",
    "        x_valid = x_valid.reshape((5000, 32, 32, 3))\n",
    "        x_test = x_test.reshape((10000, 32, 32, 3))\n",
    "        \n",
    "        return [x_train,y_train], [x_valid, y_valid], [x_test, y_test]\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        print(\"Unrecognized dataset\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad5a4305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size mnist (28, 28, 1)\n",
      "Training: (55000, 28, 28, 1) (55000,)\n",
      "Validation: (5000, 28, 28, 1) (5000,)\n",
      "Testing: (10000, 28, 28, 1) (10000,)\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, 28, 28, 1)]          0         []                            \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)          (None, 14, 14, 16)           160       ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)          (None, 14, 14, 16)           2320      ['conv2d_10[0][0]']           \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPoolin  (None, 7, 7, 16)             0         ['conv2d_11[0][0]']           \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)          (None, 7, 7, 32)             4640      ['max_pooling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)          (None, 7, 7, 32)             544       ['conv2d_11[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)          (None, 7, 7, 32)             9248      ['conv2d_13[0][0]']           \n",
      "                                                                                                  \n",
      " add_1 (Add)                 (None, 7, 7, 32)             0         ['conv2d_12[0][0]',           \n",
      "                                                                     'conv2d_14[0][0]']           \n",
      "                                                                                                  \n",
      " k_smish_3 (k_smish)         (None, 7, 7, 32)             0         ['add_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)          (None, 7, 7, 48)             13872     ['k_smish_3[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)          (None, 7, 7, 48)             20784     ['conv2d_16[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)          (None, 7, 7, 48)             1584      ['conv2d_14[0][0]']           \n",
      "                                                                                                  \n",
      " average_2 (Average)         (None, 7, 7, 48)             0         ['conv2d_17[0][0]',           \n",
      "                                                                     'conv2d_15[0][0]']           \n",
      "                                                                                                  \n",
      " k_smish_4 (k_smish)         (None, 7, 7, 48)             0         ['average_2[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)          (None, 7, 7, 48)             20784     ['k_smish_4[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)          (None, 7, 7, 48)             20784     ['conv2d_18[0][0]']           \n",
      "                                                                                                  \n",
      " average_3 (Average)         (None, 7, 7, 48)             0         ['conv2d_19[0][0]',           \n",
      "                                                                     'conv2d_15[0][0]']           \n",
      "                                                                                                  \n",
      " k_smish_5 (k_smish)         (None, 7, 7, 48)             0         ['average_3[0][0]']           \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)         (None, 2352)                 0         ['k_smish_5[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 64)                   150592    ['flatten_1[0][0]']           \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 10)                   650       ['dense_2[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 245962 (960.79 KB)\n",
      "Trainable params: 245962 (960.79 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# print(image_size+ (1,))\n",
    "dataset_name = [\"mnist\",\"mnist_fashion\",\"cifar10\", \"cifar100\"]\n",
    "data = dataset_name[0]\n",
    "if data==\"cifar10\" or data==\"cifar100\":\n",
    "    image_size =(32, 32,3) \n",
    "else:\n",
    "    image_size = (28, 28,1)\n",
    "    \n",
    "batch_size = 32\n",
    "N_classes = 10 if data!=\"cifar100\" else 100\n",
    "\n",
    "training, validation, testing = dataset_maker(data)\n",
    "x_train, y_train = training\n",
    "x_valid, y_valid = validation\n",
    "x_test, y_test = testing\n",
    "\n",
    "print(\"Dataset size\", data,image_size)\n",
    "print(\"Training:\", x_train.shape, y_train.shape)\n",
    "print(\"Validation:\", x_valid.shape, y_valid.shape)\n",
    "print(\"Testing:\", x_test.shape, y_test.shape)\n",
    "\n",
    "model = model_maker(image_size,N_classes)\n",
    "# keras.utils.plot_model(model, show_shapes=True)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be46e872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compile the model\n",
    "# model.compile(loss=keras.losses.SparseCategoricalCrossentropy(), \n",
    "#               optimizer=keras.optimizers.SGD(), \n",
    "#               metrics=[keras.metrics.SparseTopKCategoricalAccuracy(k=1)]) # first optimizer\n",
    "\n",
    "# model.compile(loss=keras.losses.SparseCategoricalCrossentropy(), \n",
    "#               optimizer=keras.optimizers.AdamW(), \n",
    "#               metrics=[keras.metrics.SparseCategoricalAccuracy()]) # second optimizer\n",
    "\n",
    "model.compile(loss=keras.losses.SparseCategoricalCrossentropy(), \n",
    "              optimizer=keras.optimizers.AdamW(), \n",
    "              metrics=[keras.metrics.SparseTopKCategoricalAccuracy(k=1)]) # second optimizer and accuracy\n",
    "image_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8299665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:From C:\\Users\\xavysp\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "1719/1719 [==============================] - 35s 18ms/step - loss: 0.1846 - sparse_top_k_categorical_accuracy: 0.9413 - val_loss: 0.0729 - val_sparse_top_k_categorical_accuracy: 0.9778\n",
      "Epoch 2/5\n",
      "1719/1719 [==============================] - 36s 21ms/step - loss: 0.0650 - sparse_top_k_categorical_accuracy: 0.9791 - val_loss: 0.0698 - val_sparse_top_k_categorical_accuracy: 0.9792\n",
      "Epoch 3/5\n",
      "1719/1719 [==============================] - 36s 21ms/step - loss: 0.0477 - sparse_top_k_categorical_accuracy: 0.9849 - val_loss: 0.0503 - val_sparse_top_k_categorical_accuracy: 0.9866\n",
      "Epoch 4/5\n",
      "1719/1719 [==============================] - 36s 21ms/step - loss: 0.0390 - sparse_top_k_categorical_accuracy: 0.9877 - val_loss: 0.0549 - val_sparse_top_k_categorical_accuracy: 0.9840\n",
      "Epoch 5/5\n",
      "1719/1719 [==============================] - 36s 21ms/step - loss: 0.0331 - sparse_top_k_categorical_accuracy: 0.9897 - val_loss: 0.0533 - val_sparse_top_k_categorical_accuracy: 0.9868\n"
     ]
    }
   ],
   "source": [
    "# start training\n",
    "epochs = 5 # 5, 10, 15, 20\n",
    "history = model.fit(x_train, y_train, epochs=epochs,\n",
    "                    validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b49008bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 10ms/step - loss: 0.0492 - sparse_top_k_categorical_accuracy: 0.9853\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04918565973639488, 0.9853000044822693]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
